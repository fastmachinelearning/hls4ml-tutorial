
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Part 6: Convolutional Neural Networks in hls4ml &#8212; hls4ml tutorial</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'part6_cnns';</script>
    <link rel="canonical" href="https://fastmachinlearning.org/hls4ml-tutorial/part6_cnns.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Part 7a: Bitstream Generation" href="part7a_bitstream.html" />
    <link rel="prev" title="Load dataset" href="part5_bdt.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="README.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/hls4ml_logo.svg" class="logo__image only-light" alt="hls4ml tutorial - Home"/>
    <script>document.write(`<img src="_static/hls4ml_logo.svg" class="logo__image only-dark" alt="hls4ml tutorial - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="README.html">
                    hls4ml-tutorial: Tutorial notebooks for hls4ml
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="part1_getting_started.html">Part 1: Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="part2_advanced_config.html">Part 2: Advanced Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="part3_compression.html">Part 3: Compression</a></li>
<li class="toctree-l1"><a class="reference internal" href="part4_quantization.html">Part 4: Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="part5_bdt.html">Load dataset</a></li>


<li class="toctree-l1 current active"><a class="current reference internal" href="#">Part 6: Convolutional Neural Networks in hls4ml</a></li>
<li class="toctree-l1"><a class="reference internal" href="part7a_bitstream.html">Part 7a: Bitstream Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="part7b_deployment.html">Part 7b: Deployment on PYNQ-Z2</a></li>
<li class="toctree-l1"><a class="reference internal" href="part7c_validation.html">Part 7c: Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="part8_symbolic_regression.html">Part 8: Symbolic Regression</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/fastmachinelearning/hls4ml-tutorial/main?urlpath=tree/part6_cnns.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/fastmachinelearning/hls4ml-tutorial/blob/main/part6_cnns.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/fastmachinelearning/hls4ml-tutorial" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/fastmachinelearning/hls4ml-tutorial/issues/new?title=Issue%20on%20page%20%2Fpart6_cnns.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/part6_cnns.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Part 6: Convolutional Neural Networks in hls4ml</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#start-with-the-neccessary-imports">Start with the neccessary imports</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fetch-the-svhn-dataset-using-tensorflow-dataset">Fetch the SVHN dataset using Tensorflow Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-model">Defining the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prune-dense-and-convolutional-layers">Prune dense and convolutional layers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-baseline">Train baseline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantization-and-the-fused-conv2d-batchnormalization-layer-in-qkeras">Quantization and the fused Conv2D+BatchNormalization layer in QKeras</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#performance">Performance</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#check-sparsity">Check sparsity</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cnns-in-hls4ml">CNNs in hls4ml</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#accuracy-with-bit-accurate-emulation">Accuracy with bit-accurate emulation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logic-synthesis">Logic synthesis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bonus-exercise-automatic-quantization-with-autoqkeras">Bonus exercise: Automatic quantization with AutoQKeras</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="part-6-convolutional-neural-networks-in-hls4ml">
<h1>Part 6: Convolutional Neural Networks in hls4ml<a class="headerlink" href="#part-6-convolutional-neural-networks-in-hls4ml" title="Link to this heading">#</a></h1>
<p>In this notebook you will learn how to train a pruned and quantized convolutional neural network (CNN) and deploy it using hls4ml. For this exercise, we will use the Street View House Numbers (SVHN) Dataset (<a class="reference external" href="http://ufldl.stanford.edu/housenumbers/">http://ufldl.stanford.edu/housenumbers/</a>).</p>
<p>The SVHN dataset consists of real-world images of house numbers extracted from Google Street View images. The format is similar to that of the MNIST dataset, but is a much more challenging real-world problem, as illustrated by the examples shown below.</p>
<p>All the images are in RGB format and have been cropped to 32x32 pixels.
Unlike MNIST, more than one digit can be present in the same image and in these cases, the center digit is used to assign a label to the image.
Each image can belong to one of 10 classes, corresponding to digits 0 through 9.</p>
<p><img alt="alt text" src="_images/test.png" /></p>
<p>The SVHN dataset consists of 73,257 images for training (and 531,131 extra samples that are easier to classify and can be used as additional training data) and 26,032 images for testing.</p>
<section id="start-with-the-neccessary-imports">
<h2>Start with the neccessary imports<a class="headerlink" href="#start-with-the-neccessary-imports" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow.compat.v2</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow_datasets</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tfds</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;PATH&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;XILINX_VITIS&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;/bin:&#39;</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;PATH&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2025-10-24 14:01:27.577582: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-10-24 14:01:27.604583: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/runner/miniconda3/envs/hls4ml-tutorial/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyError</span><span class="g g-Whitespace">                                  </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">8</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow.compat.v2</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow_datasets</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tfds</span>
<span class="ne">----&gt; </span><span class="mi">8</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;PATH&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;XILINX_VITIS&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;/bin:&#39;</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;PATH&#39;</span><span class="p">]</span>

<span class="nn">File ~/miniconda3/envs/hls4ml-tutorial/lib/python3.10/os.py:680,</span> in <span class="ni">_Environ.__getitem__</span><span class="nt">(self, key)</span>
<span class="g g-Whitespace">    </span><span class="mi">677</span>     <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">encodekey</span><span class="p">(</span><span class="n">key</span><span class="p">)]</span>
<span class="g g-Whitespace">    </span><span class="mi">678</span> <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">679</span>     <span class="c1"># raise KeyError with the original key value</span>
<span class="ne">--&gt; </span><span class="mi">680</span>     <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">681</span> <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decodevalue</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

<span class="ne">KeyError</span>: &#39;XILINX_VITIS&#39;
</pre></div>
</div>
</div>
</div>
</section>
<section id="fetch-the-svhn-dataset-using-tensorflow-dataset">
<h2>Fetch the SVHN dataset using Tensorflow Dataset<a class="headerlink" href="#fetch-the-svhn-dataset-using-tensorflow-dataset" title="Link to this heading">#</a></h2>
<p>In this part we will fetch the trainining, validation and test dataset using Tensorflow Datasets (<a class="reference external" href="https://www.tensorflow.org/datasets">https://www.tensorflow.org/datasets</a>). We will not use the ‘extra’ training in order to save time, but you could fetch it by adding <code class="docutils literal notranslate"><span class="pre">split='train[:90%]+extra'</span></code>. We will use the first 90% of the training data for training and the last 10% for validation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ds_train</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;svhn_cropped&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;train[:90%]&#39;</span><span class="p">,</span> <span class="n">with_info</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ds_test</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;svhn_cropped&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">shuffle_files</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ds_val</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;svhn_cropped&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;train[-10%:]&#39;</span><span class="p">,</span> <span class="n">shuffle_files</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ds_train</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">)</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">info</span><span class="o">.</span><span class="n">splits</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">num_examples</span><span class="p">)</span>
<span class="n">input_shape</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<span class="n">n_classes</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">num_classes</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training on </span><span class="si">{}</span><span class="s1"> samples of input shape </span><span class="si">{}</span><span class="s1">, belonging to </span><span class="si">{}</span><span class="s1"> classes&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">show_examples</span><span class="p">(</span><span class="n">ds_train</span><span class="p">,</span> <span class="n">info</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We’ll use TensorFlow Dataset to prepare our datasets. We’ll fetch the training dataset as tuples, and the test dataset as numpy arrays</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">preprocess</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">nclasses</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">label</span><span class="p">),</span> <span class="n">nclasses</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1024</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">ds_train</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">preprocess</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>  <span class="c1"># Get dataset as image and one-hot encoded labels, divided by max RGB</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">4096</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>

<span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">train_data</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">break</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X train batch shape = </span><span class="si">{}</span><span class="s2">, Y train batch shape = </span><span class="si">{}</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">example</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

<span class="n">val_data</span> <span class="o">=</span> <span class="n">ds_val</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">preprocess</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">val_data</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">val_data</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>

<span class="c1"># For  testing, we get the full dataset in memory as it&#39;s rather small.</span>
<span class="c1"># We fetch it as numpy arrays to have access to labels and images separately</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">tfds</span><span class="o">.</span><span class="n">as_numpy</span><span class="p">(</span><span class="n">tfds</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;svhn_cropped&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">as_supervised</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">,</span> <span class="n">nclasses</span><span class="o">=</span><span class="n">n_classes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X test batch shape = </span><span class="si">{}</span><span class="s2">, Y test batch shape = </span><span class="si">{}</span><span class="s2"> &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="defining-the-model">
<h2>Defining the model<a class="headerlink" href="#defining-the-model" title="Link to this heading">#</a></h2>
<p>We then need to define a model. For the lowest possible latency, each layer should have a maximum number of trainable parameters of 4096. This is due to fixed limits in the Vivado compiler, beyond which maximally unrolled (=parallel) compilation will fail. This will allow us to use <code class="docutils literal notranslate"><span class="pre">strategy</span> <span class="pre">=</span> <span class="pre">'latency'</span></code> in the hls4ml part, rather than <code class="docutils literal notranslate"><span class="pre">strategy</span> <span class="pre">=</span> <span class="pre">'resource'</span></code>, in turn resulting in lower latency</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Input</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">BatchNormalization</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Conv2D</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.regularizers</span><span class="w"> </span><span class="kn">import</span> <span class="n">l1</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">MaxPooling2D</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Activation</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Flatten</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dense</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">Model</span>

<span class="n">filters_per_conv_layer</span> <span class="o">=</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">24</span><span class="p">]</span>
<span class="n">neurons_per_dense_layer</span> <span class="o">=</span> <span class="p">[</span><span class="mi">42</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">x_in</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">filters_per_conv_layer</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Adding convolutional block </span><span class="si">{}</span><span class="s1"> with N=</span><span class="si">{}</span><span class="s1"> filters&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">f</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span>
        <span class="nb">int</span><span class="p">(</span><span class="n">f</span><span class="p">),</span>
        <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
        <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;lecun_uniform&#39;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
        <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span>
    <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;bn_conv_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv_act_</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;pool_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">neurons_per_dense_layer</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Adding dense block </span><span class="si">{}</span><span class="s1"> with N=</span><span class="si">{}</span><span class="s1"> neurons&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;lecun_uniform&#39;</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dense_</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;bn_dense_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dense_act_</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_classes</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output_dense&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x_out</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output_softmax&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x_in</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">x_out</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;keras_baseline&#39;</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Lets check if this model can be implemented completely unrolled (=parallel)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;Conv2D&#39;</span><span class="p">,</span> <span class="s1">&#39;Dense&#39;</span><span class="p">]:</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">layersize</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">layersize</span><span class="p">))</span>  <span class="c1"># 0 = weights, 1 = biases</span>
        <span class="k">if</span> <span class="n">layersize</span> <span class="o">&gt;</span> <span class="mi">4096</span><span class="p">:</span>  <span class="c1"># assuming that shape[0] is batch, i.e., &#39;None&#39;</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Layer </span><span class="si">{}</span><span class="s2"> is too large (</span><span class="si">{}</span><span class="s2">), are you sure you want to train?&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">layersize</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Looks good! It’s below the Vivado-enforced unroll limit of 4096.</p>
</section>
<section id="prune-dense-and-convolutional-layers">
<h2>Prune dense and convolutional layers<a class="headerlink" href="#prune-dense-and-convolutional-layers" title="Link to this heading">#</a></h2>
<p>Since we’ve seen in the previous notebooks that pruning can be done at no accuracy cost, let’s prune the convolutional and dense layers to 50% sparsity, skipping the output layer</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow_model_optimization</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tfmot</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow_model_optimization.sparsity</span><span class="w"> </span><span class="kn">import</span> <span class="n">keras</span> <span class="k">as</span> <span class="n">sparsity</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow_model_optimization.python.core.sparsity.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">pruning_callbacks</span>

<span class="n">NSTEPS</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">train_size</span> <span class="o">*</span> <span class="mf">0.9</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>  <span class="c1"># 90% train, 10% validation in 10-fold cross validation</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of training steps per epoch is </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">NSTEPS</span><span class="p">))</span>


<span class="c1"># Prune all convolutional and dense layers gradually from 0 to 50% sparsity every 2 epochs,</span>
<span class="c1"># ending by the 10th epoch</span>
<span class="k">def</span><span class="w"> </span><span class="nf">pruneFunction</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
    <span class="n">pruning_params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;pruning_schedule&#39;</span><span class="p">:</span> <span class="n">sparsity</span><span class="o">.</span><span class="n">PolynomialDecay</span><span class="p">(</span>
            <span class="n">initial_sparsity</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">final_sparsity</span><span class="o">=</span><span class="mf">0.50</span><span class="p">,</span> <span class="n">begin_step</span><span class="o">=</span><span class="n">NSTEPS</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">end_step</span><span class="o">=</span><span class="n">NSTEPS</span> <span class="o">*</span> <span class="mi">10</span><span class="p">,</span> <span class="n">frequency</span><span class="o">=</span><span class="n">NSTEPS</span>
        <span class="p">)</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tfmot</span><span class="o">.</span><span class="n">sparsity</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">prune_low_magnitude</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="o">**</span><span class="n">pruning_params</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">)</span> <span class="ow">and</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="s1">&#39;output_dense&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tfmot</span><span class="o">.</span><span class="n">sparsity</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">prune_low_magnitude</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="o">**</span><span class="n">pruning_params</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">layer</span>


<span class="n">model_pruned</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clone_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">clone_function</span><span class="o">=</span><span class="n">pruneFunction</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-baseline">
<h2>Train baseline<a class="headerlink" href="#train-baseline" title="Link to this heading">#</a></h2>
<p>We’re now ready to train the model! We defined the batch size and n epochs above. We won’t use callbacks that store the best weights only, since this might select a weight configuration that has not yet reached 50% sparsity.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># True if you want to retrain, false if you want to load a previsously trained model</span>

<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">30</span>

<span class="k">if</span> <span class="n">train</span><span class="p">:</span>
    <span class="n">LOSS</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">CategoricalCrossentropy</span><span class="p">()</span>
    <span class="n">OPTIMIZER</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">3e-3</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-07</span><span class="p">,</span> <span class="n">amsgrad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">model_pruned</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">LOSS</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">OPTIMIZER</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>

    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">pruning_callbacks</span><span class="o">.</span><span class="n">UpdatePruningStep</span><span class="p">(),</span>
    <span class="p">]</span>

    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">model_pruned</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">val_data</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;It took </span><span class="si">{}</span><span class="s1"> minutes to train Keras model&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">/</span> <span class="mf">60.0</span><span class="p">))</span>

    <span class="n">model_pruned</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;pruned_cnn_model.h5&#39;</span><span class="p">)</span>

<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">qkeras.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_add_supported_quantized_objects</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow_model_optimization.python.core.sparsity.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">pruning_wrapper</span>

    <span class="n">co</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">_add_supported_quantized_objects</span><span class="p">(</span><span class="n">co</span><span class="p">)</span>
    <span class="n">co</span><span class="p">[</span><span class="s1">&#39;PruneLowMagnitude&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pruning_wrapper</span><span class="o">.</span><span class="n">PruneLowMagnitude</span>
    <span class="n">model_pruned</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;pruned_cnn_model.h5&#39;</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="n">co</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You’ll notice the accuracy is lower than that in the hls4ml CNN paper (<a class="reference external" href="https://arxiv.org/abs/2101.05108">https://arxiv.org/abs/2101.05108</a>) despite the model being the same. The reson for this is that we didn’t use the <code class="docutils literal notranslate"><span class="pre">extra</span></code> training data in order to save time. If you want to futher optimize the network, increasing the training data is a good place to start. Enlarging the model architecture comes at a high latency/resource cost.</p>
</section>
<section id="quantization-and-the-fused-conv2d-batchnormalization-layer-in-qkeras">
<h2>Quantization and the fused Conv2D+BatchNormalization layer in QKeras<a class="headerlink" href="#quantization-and-the-fused-conv2d-batchnormalization-layer-in-qkeras" title="Link to this heading">#</a></h2>
<p>Let’s now create a pruned an quantized model using QKeras. For this, we will use a fused Convolutional and BatchNormalization (BN) layer from QKeras, which will further speed up the implementation when we implement the model using hls4ml.
There is currently no fused Dense+BatchNoralization layer available in QKeras, so we’ll use Keras BatchNormalization when BN follows a Dense layer for now. We’ll use the same precision everywhere, namely a bit width of 6 and 0 integer bits (this will be implemented as<code class="docutils literal notranslate"><span class="pre">&lt;6,1&gt;</span></code> in hls4ml, due to the missing sign-bit). For now, make sure to set <code class="docutils literal notranslate"><span class="pre">use_bias=True</span></code> in <code class="docutils literal notranslate"><span class="pre">QConv2DBatchnorm</span></code> to avoid problems during synthesis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">qkeras</span><span class="w"> </span><span class="kn">import</span> <span class="n">QActivation</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">qkeras</span><span class="w"> </span><span class="kn">import</span> <span class="n">QDense</span><span class="p">,</span> <span class="n">QConv2DBatchnorm</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">x_in</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">filters_per_conv_layer</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Adding fused QConv+BN block </span><span class="si">{}</span><span class="s1"> with N=</span><span class="si">{}</span><span class="s1"> filters&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">f</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">QConv2DBatchnorm</span><span class="p">(</span>
        <span class="nb">int</span><span class="p">(</span><span class="n">f</span><span class="p">),</span>
        <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
        <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">kernel_quantizer</span><span class="o">=</span><span class="s2">&quot;quantized_bits(6,0,alpha=1)&quot;</span><span class="p">,</span>
        <span class="n">bias_quantizer</span><span class="o">=</span><span class="s2">&quot;quantized_bits(6,0,alpha=1)&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;lecun_uniform&#39;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
        <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;fused_convbn_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span>
    <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">QActivation</span><span class="p">(</span><span class="s1">&#39;quantized_relu(6)&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv_act_</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;pool_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">neurons_per_dense_layer</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Adding QDense block </span><span class="si">{}</span><span class="s1"> with N=</span><span class="si">{}</span><span class="s1"> neurons&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">QDense</span><span class="p">(</span>
        <span class="n">n</span><span class="p">,</span>
        <span class="n">kernel_quantizer</span><span class="o">=</span><span class="s2">&quot;quantized_bits(6,0,alpha=1)&quot;</span><span class="p">,</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;lecun_uniform&#39;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dense_</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span>
        <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;bn_dense_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">QActivation</span><span class="p">(</span><span class="s1">&#39;quantized_relu(6)&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dense_act_</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_classes</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output_dense&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x_out</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output_softmax&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">qmodel</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x_in</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">x_out</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;qkeras&#39;</span><span class="p">)</span>

<span class="n">qmodel</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print the quantized layers</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">qkeras.autoqkeras.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">print_qmodel_summary</span>

<span class="n">print_qmodel_summary</span><span class="p">(</span><span class="n">qmodel</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You see that a bias quantizer is defined, although we are not using a bias term for the layers. This is set automatically by QKeras. In addition, you’ll note that <code class="docutils literal notranslate"><span class="pre">alpha='1'</span></code>. This sets the weight scale per channel to 1 (no scaling). The default is <code class="docutils literal notranslate"><span class="pre">alpha='auto_po2'</span></code>, which sets the weight scale per channel to be a power-of-2, such that an actual hardware implementation can be performed by just shifting the result of the convolutional/dense layer to the right or left by checking the sign of the scale and then taking the log2 of the scale.</p>
<p>Let’s now prune and train this model! If you want, you can also train the unpruned version, <code class="docutils literal notranslate"><span class="pre">qmodel</span></code> and see how the performance compares. We will stick to the pruned one here. Again, we do not use a model checkpoint which stores the best weights, in order to ensure the model is trained to the desired sparsity.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">qmodel_pruned</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clone_model</span><span class="p">(</span><span class="n">qmodel</span><span class="p">,</span> <span class="n">clone_function</span><span class="o">=</span><span class="n">pruneFunction</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">30</span>
<span class="k">if</span> <span class="n">train</span><span class="p">:</span>
    <span class="n">LOSS</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">CategoricalCrossentropy</span><span class="p">()</span>
    <span class="n">OPTIMIZER</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">3e-3</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-07</span><span class="p">,</span> <span class="n">amsgrad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">qmodel_pruned</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">LOSS</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">OPTIMIZER</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>

    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">pruning_callbacks</span><span class="o">.</span><span class="n">UpdatePruningStep</span><span class="p">(),</span>
    <span class="p">]</span>

    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">qmodel_pruned</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">val_data</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> It took </span><span class="si">{}</span><span class="s1"> minutes to train!</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">/</span> <span class="mf">60.0</span><span class="p">))</span>

    <span class="n">qmodel_pruned</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;quantized_pruned_cnn_model.h5&#39;</span><span class="p">)</span>

<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">qkeras.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_add_supported_quantized_objects</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow_model_optimization.python.core.sparsity.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">pruning_wrapper</span>

    <span class="n">co</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">_add_supported_quantized_objects</span><span class="p">(</span><span class="n">co</span><span class="p">)</span>
    <span class="n">co</span><span class="p">[</span><span class="s1">&#39;PruneLowMagnitude&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pruning_wrapper</span><span class="o">.</span><span class="n">PruneLowMagnitude</span>
    <span class="n">qmodel_pruned</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;quantized_pruned_cnn_model.h5&#39;</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="n">co</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We note that training a model quantization aware, takes around twice as long as when not quantizing during training!
The validation accuracy is very similar to that of the floating point model equivalent, despite containing significantly less information</p>
</section>
<section id="performance">
<h2>Performance<a class="headerlink" href="#performance" title="Link to this heading">#</a></h2>
<p>Let’s look at some ROC curves to compare the performance. Lets choose a few numbers so it doesn’t get confusing. Feel free to change the numbers in <code class="docutils literal notranslate"><span class="pre">labels</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predict_baseline</span> <span class="o">=</span> <span class="n">model_pruned</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">test_score_baseline</span> <span class="o">=</span> <span class="n">model_pruned</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>

<span class="n">predict_qkeras</span> <span class="o">=</span> <span class="n">qmodel_pruned</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">test_score_qkeras</span> <span class="o">=</span> <span class="n">qmodel_pruned</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Keras accuracy = </span><span class="si">{}</span><span class="s1"> , QKeras 6-bit accuracy = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_score_baseline</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">test_score_qkeras</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">metrics</span>


<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">nr</span> <span class="k">for</span> <span class="n">nr</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)]</span>  <span class="c1"># If you want to look at all the labels</span>
<span class="c1"># labels = [&#39;0&#39;,&#39;1&#39;,&#39;9&#39;] # Look at only a few labels, here for digits 0, 1 and 9</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Plotting ROC for labels </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">df_q</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">fpr</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">tpr</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">auc1</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">fpr_q</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">tpr_q</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">auc1_q</span> <span class="o">=</span> <span class="p">{}</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;#67001f&#39;</span><span class="p">,</span> <span class="s1">&#39;#b2182b&#39;</span><span class="p">,</span> <span class="s1">&#39;#d6604d&#39;</span><span class="p">,</span> <span class="s1">&#39;#f4a582&#39;</span><span class="p">,</span> <span class="s1">&#39;#fddbc7&#39;</span><span class="p">,</span> <span class="s1">&#39;#d1e5f0&#39;</span><span class="p">,</span> <span class="s1">&#39;#92c5de&#39;</span><span class="p">,</span> <span class="s1">&#39;#4393c3&#39;</span><span class="p">,</span> <span class="s1">&#39;#2166ac&#39;</span><span class="p">,</span> <span class="s1">&#39;#053061&#39;</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
    <span class="n">df</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y_test</span><span class="p">[:,</span> <span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="p">)]</span>
    <span class="n">df</span><span class="p">[</span><span class="n">label</span> <span class="o">+</span> <span class="s1">&#39;_pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predict_baseline</span><span class="p">[:,</span> <span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="p">)]</span>
    <span class="n">fpr</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="n">threshold</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="n">label</span> <span class="o">+</span> <span class="s1">&#39;_pred&#39;</span><span class="p">])</span>
    <span class="n">auc1</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="n">tpr</span><span class="p">[</span><span class="n">label</span><span class="p">])</span>

    <span class="n">df_q</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">Y_test</span><span class="p">[:,</span> <span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="p">)]</span>
    <span class="n">df_q</span><span class="p">[</span><span class="n">label</span> <span class="o">+</span> <span class="s1">&#39;_pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">predict_qkeras</span><span class="p">[:,</span> <span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="p">)]</span>
    <span class="n">fpr_q</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="n">tpr_q</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="n">threshold_q</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">df_q</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="n">df_q</span><span class="p">[</span><span class="n">label</span> <span class="o">+</span> <span class="s1">&#39;_pred&#39;</span><span class="p">])</span>
    <span class="n">auc1_q</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr_q</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="n">tpr_q</span><span class="p">[</span><span class="n">label</span><span class="p">])</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">fpr</span><span class="p">[</span><span class="n">label</span><span class="p">],</span>
        <span class="n">tpr</span><span class="p">[</span><span class="n">label</span><span class="p">],</span>
        <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">, AUC Keras = </span><span class="si">{:.1f}</span><span class="s1">% AUC QKeras = </span><span class="si">{:.1f}</span><span class="s1">%)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">auc1</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="n">auc1_q</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">),</span>
        <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span>
        <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
        <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;solid&#39;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr_q</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="n">tpr_q</span><span class="p">[</span><span class="n">label</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dotted&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">semilogx</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True Positive Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;False Positive Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figtext</span><span class="p">(</span>
    <span class="mf">0.2</span><span class="p">,</span>
    <span class="mf">0.83</span><span class="p">,</span>
    <span class="sa">r</span><span class="s1">&#39;Accuracy Keras = </span><span class="si">{:.1f}</span><span class="s1">% QKeras 8-bit = </span><span class="si">{:.1f}</span><span class="s1">%&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_score_baseline</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="n">test_score_qkeras</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">),</span>
    <span class="n">wrap</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span>
    <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.lines</span><span class="w"> </span><span class="kn">import</span> <span class="n">Line2D</span>

<span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)]</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.legend</span><span class="w"> </span><span class="kn">import</span> <span class="n">Legend</span>

<span class="n">leg</span> <span class="o">=</span> <span class="n">Legend</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">lines</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Keras&#39;</span><span class="p">,</span> <span class="s1">&#39;QKeras&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">leg</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The difference in AUC between the fp32 Keras model and the 8-bit QKeras model, is small, as we have seen for the previous examples. You can find a bonus exercise below, <strong>Bonus: Automatic quantization</strong>, where we’ll use AutoQKeras to find the best heterogeneously quantized model, given a set of resource and accuracy constriants.</p>
<section id="check-sparsity">
<h3>Check sparsity<a class="headerlink" href="#check-sparsity" title="Link to this heading">#</a></h3>
<p>Let’s also check the per-layer sparsity:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">doWeights</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">allWeightsByLayer</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_name</span><span class="p">)</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;batch&quot;</span><span class="p">)</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">get_weights</span><span class="p">())</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">allWeightsByLayer</span><span class="p">[</span><span class="n">layer</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Layer </span><span class="si">{}</span><span class="s1">: </span><span class="si">% o</span><span class="s1">f zeros = </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">weights</span><span class="p">)))</span>

    <span class="n">labelsW</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">histosW</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">allWeightsByLayer</span><span class="o">.</span><span class="n">keys</span><span class="p">())):</span>
        <span class="n">labelsW</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="n">histosW</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">allWeightsByLayer</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>

    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">histosW</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;stepfilled&#39;</span><span class="p">,</span> <span class="n">stacked</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">labelsW</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Number of Weights&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Weights&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figtext</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.38</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span> <span class="n">wrap</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>


<span class="n">doWeights</span><span class="p">(</span><span class="n">model_pruned</span><span class="p">)</span>
<span class="n">doWeights</span><span class="p">(</span><span class="n">qmodel_pruned</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We see that 50% of the weights per layer are set to zero, as expected.
Now, let’s synthesize the floating point Keras model and the QKeras quantized model!</p>
</section>
</section>
<section id="cnns-in-hls4ml">
<h2>CNNs in hls4ml<a class="headerlink" href="#cnns-in-hls4ml" title="Link to this heading">#</a></h2>
<p>In this part, we will take the two models we trained above (the floating-point 32 Keras model and the 6-bit QKeras model), and synthesize them with hls4ml. Although your models are probably already in memory, let’s load them from scratch. We need to pass the appropriate custom QKeras/pruning layers when loading, and remove the pruning parameters that were saved together with the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow_model_optimization.sparsity.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">strip_pruning</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow_model_optimization.python.core.sparsity.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">pruning_wrapper</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">qkeras.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">_add_supported_quantized_objects</span>

<span class="n">co</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">_add_supported_quantized_objects</span><span class="p">(</span><span class="n">co</span><span class="p">)</span>
<span class="n">co</span><span class="p">[</span><span class="s1">&#39;PruneLowMagnitude&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pruning_wrapper</span><span class="o">.</span><span class="n">PruneLowMagnitude</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;pruned_cnn_model.h5&#39;</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="n">co</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">strip_pruning</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="n">qmodel</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;quantized_pruned_cnn_model.h5&#39;</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="n">co</span><span class="p">)</span>
<span class="n">qmodel</span> <span class="o">=</span> <span class="n">strip_pruning</span><span class="p">(</span><span class="n">qmodel</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now, we need to define the hls4ml and Vivado configurations. Two things will change with respect to what was done in the previous exercises. First, we will use <code class="docutils literal notranslate"><span class="pre">io_type='io_stream'</span></code> in the Vitis_HLS configuration.</p>
<hr class="docutils" />
<p><strong><strong>You must use <code class="docutils literal notranslate"><span class="pre">io_type='io_stream'</span></code> if attempting to synthesize a large convolutional neural network.</strong></strong></p>
<hr class="docutils" />
<p>The CNN implementation in hls4ml is based on streams, which are synthesized in hardware as first in, first out (FIFO) buffers. Shift registers are used to keep track of the last  <code class="docutils literal notranslate"><span class="pre">&lt;kernel</span> <span class="pre">height</span> <span class="pre">-</span> <span class="pre">1&gt;</span></code> rows of input pixels, and maintains a shifting snapshot of the convolution kernel.</p>
<p>This is illustrated  in the gif below. Here, the input image is at the top-left and the output image at the bottom left. The top right image shows the internal state of the shift registers and convolutional kernel. The red square indicates the current pixels contained within the convolutional kernel.</p>
<p><img alt="alt text" src="_images/conv2d_animation.gif" /></p>
<p>Lastly, we will use <code class="docutils literal notranslate"><span class="pre">['Strategy']</span> <span class="pre">=</span> <span class="pre">'Latency'</span></code> for all the layers in the hls4ml configuration. If one layer would have &gt;4096 elements, we sould set <code class="docutils literal notranslate"><span class="pre">['Strategy']</span> <span class="pre">=</span> <span class="pre">'Resource'</span></code> for that layer, or increase the reuse factor by hand. You can find examples of how to do this below.</p>
<p><strong>NOTE</strong> Using <code class="docutils literal notranslate"><span class="pre">auto</span></code> precision can lead to undesired side effects. In case of this model, the bit width used for the output of the last fully connected layer is larger than can be reasonably represented with the look-up table in the softmax implementation. We therefore need to restrict it by hand to achieve proper results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">hls4ml</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">plotting</span>

<span class="c1"># First, the baseline model</span>
<span class="n">hls_config</span> <span class="o">=</span> <span class="n">hls4ml</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">config_from_keras_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">granularity</span><span class="o">=</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;Vitis&#39;</span><span class="p">,</span> <span class="n">default_precision</span><span class="o">=</span><span class="s1">&#39;ap_fixed&lt;16,6&gt;&#39;</span>
<span class="p">)</span>
<span class="n">hls_config</span><span class="p">[</span><span class="s1">&#39;LayerName&#39;</span><span class="p">][</span><span class="s1">&#39;output_dense&#39;</span><span class="p">][</span><span class="s1">&#39;Precision&#39;</span><span class="p">][</span><span class="s1">&#39;result&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;fixed&lt;16,6,RND,SAT&gt;&#39;</span>
<span class="n">plotting</span><span class="o">.</span><span class="n">print_dict</span><span class="p">(</span><span class="n">hls_config</span><span class="p">)</span>


<span class="n">hls_model</span> <span class="o">=</span> <span class="n">hls4ml</span><span class="o">.</span><span class="n">converters</span><span class="o">.</span><span class="n">convert_from_keras_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">hls_config</span><span class="o">=</span><span class="n">hls_config</span><span class="p">,</span>
    <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;Vitis&#39;</span><span class="p">,</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s1">&#39;model_1/hls4ml_prj&#39;</span><span class="p">,</span>
    <span class="n">part</span><span class="o">=</span><span class="s1">&#39;xcu250-figd2104-2L-e&#39;</span><span class="p">,</span>
    <span class="n">io_type</span><span class="o">=</span><span class="s1">&#39;io_stream&#39;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">hls_model</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s get a nice overview over the various shapes and precisions used for each layer through <code class="docutils literal notranslate"><span class="pre">hls4ml.utils.plot_model</span></code>, as well as look at the weight profile using <code class="docutils literal notranslate"><span class="pre">hls4ml.model.profiling.numerical</span></code>. The weight profiling returns two plots: Before (top) and after (bottom) various optimizations applied to the HLS model before the final translation to HLS, for instance the fusing of Dense and BatchNormalization layers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hls4ml</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">plot_model</span><span class="p">(</span><span class="n">hls_model</span><span class="p">,</span> <span class="n">show_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_precision</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">to_file</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">hls4ml.model.profiling</span><span class="w"> </span><span class="kn">import</span> <span class="n">numerical</span>

<span class="n">numerical</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">hls_model</span><span class="o">=</span><span class="n">hls_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The colored boxes are the distribution of the weights of the model, and the gray band illustrates the numerical range covered by the chosen fixed point precision. As we configured, this model uses a precision of <code class="docutils literal notranslate"><span class="pre">ap_fixed&lt;16,6&gt;</span></code> for the weights and biases of all layers of the model.</p>
<p>Let’s now build our QKeras model.</p>
<p><strong>NOTE</strong> Using <code class="docutils literal notranslate"><span class="pre">auto</span></code> precision can lead to undesired side effects. In case of this model, the bit width used for the output of the last fully connected layer is larger than can be reasonably represented with the look-up table in the softmax implementation. We therefore need to restrict it by hand to achieve proper results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Then the QKeras model</span>
<span class="n">hls_config_q</span> <span class="o">=</span> <span class="n">hls4ml</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">config_from_keras_model</span><span class="p">(</span><span class="n">qmodel</span><span class="p">,</span> <span class="n">granularity</span><span class="o">=</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;Vitis&#39;</span><span class="p">)</span>
<span class="n">hls_config_q</span><span class="p">[</span><span class="s1">&#39;LayerName&#39;</span><span class="p">][</span><span class="s1">&#39;output_dense&#39;</span><span class="p">][</span><span class="s1">&#39;Precision&#39;</span><span class="p">][</span><span class="s1">&#39;result&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;fixed&lt;16,6,RND,SAT&gt;&#39;</span>

<span class="n">plotting</span><span class="o">.</span><span class="n">print_dict</span><span class="p">(</span><span class="n">hls_config_q</span><span class="p">)</span>

<span class="n">hls_model_q</span> <span class="o">=</span> <span class="n">hls4ml</span><span class="o">.</span><span class="n">converters</span><span class="o">.</span><span class="n">convert_from_keras_model</span><span class="p">(</span>
    <span class="n">qmodel</span><span class="p">,</span> <span class="n">hls_config</span><span class="o">=</span><span class="n">hls_config_q</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="s1">&#39;quantized_pruned_cnn&#39;</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;Vitis&#39;</span><span class="p">,</span> <span class="n">io_type</span><span class="o">=</span><span class="s1">&#39;io_stream&#39;</span>
<span class="p">)</span>

<span class="n">hls_model_q</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s plot the model and profile the weights her too</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">numerical</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">qmodel</span><span class="p">,</span> <span class="n">hls_model</span><span class="o">=</span><span class="n">hls_model_q</span><span class="p">)</span>
<span class="n">hls4ml</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">plot_model</span><span class="p">(</span><span class="n">hls_model_q</span><span class="p">,</span> <span class="n">show_shapes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_precision</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">to_file</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>For the 6-bit QKeras model, we see that different precisions are used for different layers.</p>
<section id="accuracy-with-bit-accurate-emulation">
<h3>Accuracy with bit-accurate emulation<a class="headerlink" href="#accuracy-with-bit-accurate-emulation" title="Link to this heading">#</a></h3>
<p>Let’s check that the hls4ml accuracy matches the original. This usually takes some time, so let’s do it over a reduced dataset</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_test_reduced</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[:</span><span class="mi">3000</span><span class="p">]</span>
<span class="n">Y_test_reduced</span> <span class="o">=</span> <span class="n">Y_test</span><span class="p">[:</span><span class="mi">3000</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_predict</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_reduced</span><span class="p">)</span>
<span class="n">y_predict_hls4ml</span> <span class="o">=</span> <span class="n">hls_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">X_test_reduced</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_predict_q</span> <span class="o">=</span> <span class="n">qmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_reduced</span><span class="p">)</span>
<span class="n">y_predict_hls4ml_q</span> <span class="o">=</span> <span class="n">hls_model_q</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">X_test_reduced</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">plotting</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>


<span class="k">def</span><span class="w"> </span><span class="nf">plotROC</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_pred_hls4ml</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Model&quot;</span><span class="p">):</span>
    <span class="n">accuracy_keras</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">accuracy_hls4ml</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred_hls4ml</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy Keras:  </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy_keras</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy hls4ml: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy_hls4ml</span><span class="p">))</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">nr</span> <span class="k">for</span> <span class="n">nr</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">)])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># reset the colors</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">makeRoc</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">y_pred_hls4ml</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">nr</span> <span class="k">for</span> <span class="n">nr</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">)],</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

    <span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.lines</span><span class="w"> </span><span class="kn">import</span> <span class="n">Line2D</span>

    <span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">),</span> <span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)]</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.legend</span><span class="w"> </span><span class="kn">import</span> <span class="n">Legend</span>

    <span class="n">leg</span> <span class="o">=</span> <span class="n">Legend</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">lines</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Keras&#39;</span><span class="p">,</span> <span class="s1">&#39;hls4ml&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">leg</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figtext</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.38</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">wrap</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>


<span class="c1"># Plot the pruned floating point model:</span>
<span class="n">plotROC</span><span class="p">(</span><span class="n">Y_test_reduced</span><span class="p">,</span> <span class="n">y_predict</span><span class="p">,</span> <span class="n">y_predict_hls4ml</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Keras&quot;</span><span class="p">)</span>

<span class="c1"># Plot the pruned and quantized QKeras model</span>
<span class="n">plotROC</span><span class="p">(</span><span class="n">Y_test_reduced</span><span class="p">,</span> <span class="n">y_predict_q</span><span class="p">,</span> <span class="n">y_predict_hls4ml_q</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;QKeras&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Looks good! Let’s synthesize the models.</p>
</section>
</section>
<section id="logic-synthesis">
<h2>Logic synthesis<a class="headerlink" href="#logic-synthesis" title="Link to this heading">#</a></h2>
<p>This takes quite a while for CNN models, up to one hour for the models considered here. In the interest of time, we have therefore provided the neccessary reports for the models considered. You can also synthesize them yourself if you have time, and as usual follow the progress using <code class="docutils literal notranslate"><span class="pre">tail</span> <span class="pre">-f</span> <span class="pre">pruned_cnn/vivado_hls.log</span></code> and <code class="docutils literal notranslate"><span class="pre">tail</span> <span class="pre">-f</span> <span class="pre">quantized_pruned_cnn/vivado_hls.log</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">synth</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Only if you want to synthesize the models yourself (&gt;1h per model) rather than look at the provided reports.</span>
<span class="k">if</span> <span class="n">synth</span><span class="p">:</span>
    <span class="n">hls_model</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">csim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">synth</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">vsynth</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">hls_model_q</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">csim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">synth</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">vsynth</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We extract the latency from the C synthesis, namely the report in <code class="docutils literal notranslate"><span class="pre">&lt;project_dir&gt;/myproject_prj/solution1/syn/report/myproject_csynth.rpt</span></code>. A more accurate latency estimate can be obtained from running cosim by passing <code class="docutils literal notranslate"><span class="pre">hls_model.build(csim=False,</span> <span class="pre">synth=True,</span> <span class="pre">vsynth=True,</span> <span class="pre">cosim=True)</span></code> ( = C/RTL cosimulation, synthesised HLS code is run on a simulator and tested on C test bench) but this takes a lot of time so we will skip it here.
The resource estimates are obtained from the Vivado logic synthesis, and can be extracted from the report in <code class="docutils literal notranslate"><span class="pre">&lt;project_dir&gt;/vivado_synth.rpt</span></code>. Let’s fetch the most relevant numbers:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">getReports</span><span class="p">(</span><span class="n">indir</span><span class="p">):</span>
    <span class="n">data_</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="n">report_vsynth</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">/vivado_synth.rpt&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">indir</span><span class="p">))</span>
    <span class="n">report_csynth</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1">/myproject_prj/solution1/syn/report/myproject_csynth.rpt&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">indir</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">report_vsynth</span><span class="o">.</span><span class="n">is_file</span><span class="p">()</span> <span class="ow">and</span> <span class="n">report_csynth</span><span class="o">.</span><span class="n">is_file</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Found valid vsynth and synth in </span><span class="si">{}</span><span class="s1">! Fetching numbers&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">indir</span><span class="p">))</span>

        <span class="c1"># Get the resources from the logic synthesis report</span>
        <span class="k">with</span> <span class="n">report_vsynth</span><span class="o">.</span><span class="n">open</span><span class="p">()</span> <span class="k">as</span> <span class="n">report</span><span class="p">:</span>
            <span class="n">lines</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">report</span><span class="o">.</span><span class="n">readlines</span><span class="p">())</span>
            <span class="n">data_</span><span class="p">[</span><span class="s1">&#39;lut&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;CLB LUTs*&#39;</span> <span class="ow">in</span> <span class="n">line</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">])][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="p">)[</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">data_</span><span class="p">[</span><span class="s1">&#39;ff&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;CLB Registers&#39;</span> <span class="ow">in</span> <span class="n">line</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">])][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="p">)[</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">data_</span><span class="p">[</span><span class="s1">&#39;bram&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;Block RAM Tile&#39;</span> <span class="ow">in</span> <span class="n">line</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">])][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="p">)[</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">data_</span><span class="p">[</span><span class="s1">&#39;dsp&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;DSPs&#39;</span> <span class="ow">in</span> <span class="n">line</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">])][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="p">)[</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">data_</span><span class="p">[</span><span class="s1">&#39;lut_rel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;CLB LUTs*&#39;</span> <span class="ow">in</span> <span class="n">line</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">])][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="p">)[</span><span class="mi">5</span><span class="p">])</span>
            <span class="n">data_</span><span class="p">[</span><span class="s1">&#39;ff_rel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;CLB Registers&#39;</span> <span class="ow">in</span> <span class="n">line</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">])][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="p">)[</span><span class="mi">5</span><span class="p">])</span>
            <span class="n">data_</span><span class="p">[</span><span class="s1">&#39;bram_rel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;Block RAM Tile&#39;</span> <span class="ow">in</span> <span class="n">line</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">])][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="p">)[</span><span class="mi">5</span><span class="p">])</span>
            <span class="n">data_</span><span class="p">[</span><span class="s1">&#39;dsp_rel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">lines</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;DSPs&#39;</span> <span class="ow">in</span> <span class="n">line</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">])][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="p">)[</span><span class="mi">5</span><span class="p">])</span>

        <span class="k">with</span> <span class="n">report_csynth</span><span class="o">.</span><span class="n">open</span><span class="p">()</span> <span class="k">as</span> <span class="n">report</span><span class="p">:</span>
            <span class="n">lines</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">report</span><span class="o">.</span><span class="n">readlines</span><span class="p">())</span>
            <span class="n">lat_line</span> <span class="o">=</span> <span class="n">lines</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39;Latency (cycles)&#39;</span> <span class="ow">in</span> <span class="n">line</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">3</span><span class="p">]</span>
            <span class="n">data_</span><span class="p">[</span><span class="s1">&#39;latency_clks&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">lat_line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="p">)[</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">data_</span><span class="p">[</span><span class="s1">&#39;latency_mus&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">lat_line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="p">)[</span><span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="mf">5.0</span> <span class="o">/</span> <span class="mf">1000.0</span>
            <span class="n">data_</span><span class="p">[</span><span class="s1">&#39;latency_ii&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">lat_line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="p">)[</span><span class="mi">6</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">data_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pprint</span>

<span class="n">data_pruned_ref</span> <span class="o">=</span> <span class="n">getReports</span><span class="p">(</span><span class="s1">&#39;pruned_cnn&#39;</span><span class="p">)</span>
<span class="n">data_quantized_pruned</span> <span class="o">=</span> <span class="n">getReports</span><span class="p">(</span><span class="s1">&#39;quantized_pruned_cnn&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Resource usage and latency: Pruned&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">data_pruned_ref</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Resource usage and latency: Pruned + quantized&quot;</span><span class="p">)</span>
<span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">data_quantized_pruned</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We see that the latency is of around 5 microseconds for both the quantized and the unquantized model, but that the resources are signifcantly reduced using QKeras.</p>
<p>Congratulations! You have now reached the end of this notebook. If you have some spare time, you can have a look at the bonus exercise below, where you will learn how to perform a bayesian optimization over the QKeras quantizers in order to obtain an optimally heterogeneously quantized model.</p>
</section>
<section id="bonus-exercise-automatic-quantization-with-autoqkeras">
<h2>Bonus exercise: Automatic quantization with AutoQKeras<a class="headerlink" href="#bonus-exercise-automatic-quantization-with-autoqkeras" title="Link to this heading">#</a></h2>
<p>In this bonus exercise, you will learn how to find the optimal heterogeneously quantized model using AutoQKeras.
For more details, you can look at the <a class="reference external" href="https://github.com/google/qkeras/blob/master/notebook/AutoQKeras.ipynb">AutoQKeras notebook</a>.</p>
<p>Let’s first check the estimated energy consumption of the QKeras 6-bit model using QTools. By setting <code class="docutils literal notranslate"><span class="pre">for_reference=True</span></code> you can print out the unquantized model energy consumption and compare the two. Note that this only works for QKeras layers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">filters_per_conv_layer</span> <span class="o">=</span> <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">24</span><span class="p">]</span>
<span class="n">neurons_per_dense_layer</span> <span class="o">=</span> <span class="p">[</span><span class="mi">42</span><span class="p">,</span> <span class="mi">64</span><span class="p">]</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">x_in</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">filters_per_conv_layer</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Adding convolutional block </span><span class="si">{}</span><span class="s1"> with N=</span><span class="si">{}</span><span class="s1"> filters&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">f</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Conv2D</span><span class="p">(</span>
        <span class="nb">int</span><span class="p">(</span><span class="n">f</span><span class="p">),</span>
        <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
        <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;lecun_uniform&#39;</span><span class="p">,</span>
        <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span>
        <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span>
    <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;bn_conv_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;conv_act_</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;pool_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">neurons_per_dense_layer</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">((</span><span class="s1">&#39;Adding dense block </span><span class="si">{}</span><span class="s1"> with N=</span><span class="si">{}</span><span class="s1"> neurons&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;lecun_uniform&#39;</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">l1</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dense_</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;bn_dense_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dense_act_</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_classes</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output_dense&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x_out</span> <span class="o">=</span> <span class="n">Activation</span><span class="p">(</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;output_softmax&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">baseline_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x_in</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">x_out</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;keras_baseline&#39;</span><span class="p">)</span>

<span class="n">LOSS</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">CategoricalCrossentropy</span><span class="p">()</span>
<span class="n">OPTIMIZER</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">3e-3</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-07</span><span class="p">,</span> <span class="n">amsgrad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">baseline_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">LOSS</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">OPTIMIZER</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">qkeras</span><span class="w"> </span><span class="kn">import</span> <span class="n">print_qstats</span>

<span class="c1"># for automatic quantization</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pprint</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">qkeras.autoqkeras</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">qkeras</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">qkeras.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">model_quantize</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">qkeras.qtools</span><span class="w"> </span><span class="kn">import</span> <span class="n">run_qtools</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">qkeras.qtools</span><span class="w"> </span><span class="kn">import</span> <span class="n">settings</span> <span class="k">as</span> <span class="n">qtools_settings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow_model_optimization.python.core.sparsity.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">pruning_wrapper</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">qkeras</span><span class="w"> </span><span class="kn">import</span> <span class="n">quantized_bits</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">qkeras</span><span class="w"> </span><span class="kn">import</span> <span class="n">QDense</span><span class="p">,</span> <span class="n">QActivation</span>

<span class="n">q</span> <span class="o">=</span> <span class="n">run_qtools</span><span class="o">.</span><span class="n">QTools</span><span class="p">(</span>
    <span class="n">baseline_model</span><span class="p">,</span>
    <span class="n">process</span><span class="o">=</span><span class="s2">&quot;horowitz&quot;</span><span class="p">,</span>
    <span class="n">source_quantizers</span><span class="o">=</span><span class="p">[</span><span class="n">quantized_bits</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>
    <span class="n">is_inference</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">weights_path</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">keras_quantizer</span><span class="o">=</span><span class="s2">&quot;fp16&quot;</span><span class="p">,</span>
    <span class="n">keras_accumulator</span><span class="o">=</span><span class="s2">&quot;fp16&quot;</span><span class="p">,</span>
    <span class="n">for_reference</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">q</span><span class="o">.</span><span class="n">qtools_stats_print</span><span class="p">()</span>

<span class="n">energy_dict</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">pe</span><span class="p">(</span>
    <span class="n">weights_on_memory</span><span class="o">=</span><span class="s2">&quot;fixed&quot;</span><span class="p">,</span> <span class="n">activations_on_memory</span><span class="o">=</span><span class="s2">&quot;fixed&quot;</span><span class="p">,</span> <span class="n">min_sram_size</span><span class="o">=</span><span class="mi">8</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span><span class="p">,</span> <span class="n">rd_wr_on_io</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="c1"># get stats of energy distribution in each layer</span>
<span class="n">energy_profile</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">extract_energy_profile</span><span class="p">(</span><span class="n">qtools_settings</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">include_energy</span><span class="p">,</span> <span class="n">energy_dict</span><span class="p">)</span>
<span class="c1"># extract sum of energy of each layer according to the rule specified in</span>
<span class="c1"># qtools_settings.cfg.include_energy</span>
<span class="n">total_energy</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">extract_energy_sum</span><span class="p">(</span><span class="n">qtools_settings</span><span class="o">.</span><span class="n">cfg</span><span class="o">.</span><span class="n">include_energy</span><span class="p">,</span> <span class="n">energy_dict</span><span class="p">)</span>

<span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">energy_profile</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total energy: </span><span class="si">{:.6f}</span><span class="s2"> uJ&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">total_energy</span> <span class="o">/</span> <span class="mf">1000000.0</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Now, lets use AutoQKeras to find an optimally heterogeneously quantized model for us. For more details, check the AutoQKeras tutorial linked above. As baseline model, we’ll use the pruned floating point Keras model from above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># These are the quantizers we&#39;ll test in the bayesian optimization</span>
<span class="n">quantization_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;kernel&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;quantized_bits(2,0,1,alpha=1.0)&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="s2">&quot;quantized_bits(4,0,1,alpha=1.0)&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
        <span class="s2">&quot;quantized_bits(6,0,1,alpha=1.0)&quot;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
        <span class="s2">&quot;quantized_bits(8,0,1,alpha=1.0)&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s2">&quot;bias&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;quantized_bits(2,0,1,alpha=1.0)&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="s2">&quot;quantized_bits(4,0,1,alpha=1.0)&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
        <span class="s2">&quot;quantized_bits(6,0,1,alpha=1.0)&quot;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
        <span class="s2">&quot;quantized_bits(8,0,1,alpha=1.0)&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s2">&quot;activation&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;quantized_relu(3,1)&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s2">&quot;quantized_relu(4,2)&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
        <span class="s2">&quot;quantized_relu(8,2)&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
        <span class="s2">&quot;quantized_relu(8,4)&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
        <span class="s2">&quot;quantized_relu(16,6)&quot;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s2">&quot;linear&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;quantized_bits(2,0,1,alpha=1.0)&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="s2">&quot;quantized_bits(4,0,1,alpha=1.0)&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
        <span class="s2">&quot;quantized_bits(6,0,1,alpha=1.0)&quot;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span>
        <span class="s2">&quot;quantized_bits(8,0,1,alpha=1.0)&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="c1"># These are the layer types we will quantize</span>
<span class="n">limit</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Dense&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span>
    <span class="s2">&quot;Conv2D&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span>
    <span class="s2">&quot;Activation&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">16</span><span class="p">],</span>
<span class="p">}</span>

<span class="c1"># Use this if you want to minimize the model bit size</span>
<span class="n">goal_bits</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;bits&quot;</span><span class="p">,</span>
    <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;delta_p&quot;</span><span class="p">:</span> <span class="mf">8.0</span><span class="p">,</span>  <span class="c1"># We tolerate up to a +8% accuracy change</span>
        <span class="s2">&quot;delta_n&quot;</span><span class="p">:</span> <span class="mf">8.0</span><span class="p">,</span>  <span class="c1"># We tolerate down to a -8% accuracy change</span>
        <span class="s2">&quot;rate&quot;</span><span class="p">:</span> <span class="mf">2.0</span><span class="p">,</span>  <span class="c1"># We want a x2 times smaller model</span>
        <span class="s2">&quot;stress&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>  <span class="c1"># Force the reference model size to be smaller by setting stress&lt;1</span>
        <span class="s2">&quot;input_bits&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
        <span class="s2">&quot;output_bits&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
        <span class="s2">&quot;ref_bits&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
        <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;default&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">,</span> <span class="s2">&quot;activations&quot;</span><span class="p">]},</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="c1"># Use this if you want to minimize the model energy consumption</span>
<span class="n">goal_energy</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;energy&quot;</span><span class="p">,</span>
    <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;delta_p&quot;</span><span class="p">:</span> <span class="mf">8.0</span><span class="p">,</span>
        <span class="s2">&quot;delta_n&quot;</span><span class="p">:</span> <span class="mf">8.0</span><span class="p">,</span>
        <span class="s2">&quot;rate&quot;</span><span class="p">:</span> <span class="mf">2.0</span><span class="p">,</span>
        <span class="s2">&quot;stress&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="s2">&quot;process&quot;</span><span class="p">:</span> <span class="s2">&quot;horowitz&quot;</span><span class="p">,</span>
        <span class="s2">&quot;parameters_on_memory&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;sram&quot;</span><span class="p">,</span> <span class="s2">&quot;sram&quot;</span><span class="p">],</span>
        <span class="s2">&quot;activations_on_memory&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;sram&quot;</span><span class="p">,</span> <span class="s2">&quot;sram&quot;</span><span class="p">],</span>
        <span class="s2">&quot;rd_wr_on_io&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
        <span class="s2">&quot;min_sram_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="s2">&quot;source_quantizers&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;fp32&quot;</span><span class="p">],</span>
        <span class="s2">&quot;reference_internal&quot;</span><span class="p">:</span> <span class="s2">&quot;int8&quot;</span><span class="p">,</span>
        <span class="s2">&quot;reference_accumulator&quot;</span><span class="p">:</span> <span class="s2">&quot;int32&quot;</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="n">run_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;goal&quot;</span><span class="p">:</span> <span class="n">goal_energy</span><span class="p">,</span>
    <span class="s2">&quot;quantization_config&quot;</span><span class="p">:</span> <span class="n">quantization_config</span><span class="p">,</span>
    <span class="s2">&quot;learning_rate_optimizer&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s2">&quot;transfer_weights&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>  <span class="c1"># Randomely initialize weights</span>
    <span class="s2">&quot;mode&quot;</span><span class="p">:</span> <span class="s2">&quot;bayesian&quot;</span><span class="p">,</span>  <span class="c1"># This can be bayesian,random,hyperband</span>
    <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>
    <span class="s2">&quot;limit&quot;</span><span class="p">:</span> <span class="n">limit</span><span class="p">,</span>
    <span class="s2">&quot;tune_filters&quot;</span><span class="p">:</span> <span class="s2">&quot;layer&quot;</span><span class="p">,</span>
    <span class="s2">&quot;tune_filters_exceptions&quot;</span><span class="p">:</span> <span class="s2">&quot;^output&quot;</span><span class="p">,</span>
    <span class="s2">&quot;distribution_strategy&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
    <span class="s2">&quot;max_trials&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>  <span class="c1"># Let&#39;s just do 5 trials for this demonstrator, ideally you should do as many as possible</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">qkeras.autoqkeras</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoQKeras</span>

<span class="n">autoqk</span> <span class="o">=</span> <span class="n">AutoQKeras</span><span class="p">(</span><span class="n">baseline_model</span><span class="p">,</span> <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;autoq_cnn&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;acc&quot;</span><span class="p">],</span> <span class="n">custom_objects</span><span class="o">=</span><span class="p">{},</span> <span class="o">**</span><span class="n">run_config</span><span class="p">)</span>
<span class="n">autoqk</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">val_data</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="n">aqmodel</span> <span class="o">=</span> <span class="n">autoqk</span><span class="o">.</span><span class="n">get_best_model</span><span class="p">()</span>
<span class="n">print_qmodel_summary</span><span class="p">(</span><span class="n">aqmodel</span><span class="p">)</span>

<span class="c1"># Train for the full epochs</span>
<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<span class="p">]</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">aqmodel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="n">val_data</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> It took </span><span class="si">{}</span><span class="s1"> minutes to train!</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">/</span> <span class="mf">60.0</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This model has some remnants from the optimization procedure attached to it, so let&#39;s define a new one</span>
<span class="n">aqmodel</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="s2">&quot;autoqkeras_cnn_weights.h5&quot;</span><span class="p">)</span>

<span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">aqmodel</span><span class="o">.</span><span class="n">layers</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>

<span class="n">new_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">])</span>
<span class="n">LOSS</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">CategoricalCrossentropy</span><span class="p">()</span>
<span class="n">OPTIMIZER</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">3e-3</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-07</span><span class="p">,</span> <span class="n">amsgrad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">new_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">LOSS</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">OPTIMIZER</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">new_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="n">new_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s2">&quot;autoqkeras_cnn_weights.h5&quot;</span><span class="p">)</span>
<span class="n">print_qmodel_summary</span><span class="p">(</span><span class="n">new_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s check what the best heterogeneously quantized model looks like (keep in mind we only did a few trials, the optimization obviosuly didn’t have time to converge at the minimum but yo get the idea!)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hls_config_aq</span> <span class="o">=</span> <span class="n">hls4ml</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">config_from_keras_model</span><span class="p">(</span><span class="n">new_model</span><span class="p">,</span> <span class="n">granularity</span><span class="o">=</span><span class="s1">&#39;name&#39;</span><span class="p">)</span>
<span class="n">hls_config_aq</span><span class="p">[</span><span class="s1">&#39;Model&#39;</span><span class="p">][</span><span class="s1">&#39;ReuseFactor&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">hls_config_aq</span><span class="p">[</span><span class="s1">&#39;Model&#39;</span><span class="p">][</span><span class="s1">&#39;Precision&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;ap_fixed&lt;16,6&gt;&#39;</span>
<span class="n">hls_config_aq</span><span class="p">[</span><span class="s1">&#39;LayerName&#39;</span><span class="p">][</span><span class="s1">&#39;output_softmax&#39;</span><span class="p">][</span><span class="s1">&#39;Strategy&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;Stable&#39;</span>
<span class="n">plotting</span><span class="o">.</span><span class="n">print_dict</span><span class="p">(</span><span class="n">hls_config_aq</span><span class="p">)</span>

<span class="n">cfg_aq</span> <span class="o">=</span> <span class="n">hls4ml</span><span class="o">.</span><span class="n">converters</span><span class="o">.</span><span class="n">create_config</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;Vivado&#39;</span><span class="p">)</span>
<span class="n">cfg_aq</span><span class="p">[</span><span class="s1">&#39;IOType&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;io_stream&#39;</span>  <span class="c1"># Must set this if using CNNs!</span>
<span class="n">cfg_aq</span><span class="p">[</span><span class="s1">&#39;HLSConfig&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">hls_config_aq</span>
<span class="n">cfg_aq</span><span class="p">[</span><span class="s1">&#39;KerasModel&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_model</span>
<span class="n">cfg_aq</span><span class="p">[</span><span class="s1">&#39;OutputDir&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;autoqkeras_cnn/&#39;</span>
<span class="n">cfg_aq</span><span class="p">[</span><span class="s1">&#39;XilinxPart&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;xcu250-figd2104-2L-e&#39;</span>

<span class="n">hls_model_aq</span> <span class="o">=</span> <span class="n">hls4ml</span><span class="o">.</span><span class="n">converters</span><span class="o">.</span><span class="n">keras_to_hls</span><span class="p">(</span><span class="n">cfg_aq</span><span class="p">)</span>
<span class="n">hls_model_aq</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_predict_aq</span> <span class="o">=</span> <span class="n">aqmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_reduced</span><span class="p">)</span>
<span class="n">y_predict_hls4ml_aq</span> <span class="o">=</span> <span class="n">hls_model_aq</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">X_test_reduced</span><span class="p">))</span>


<span class="n">accuracy_keras</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y_test_reduced</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_predict_aq</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
<span class="n">accuracy_hls4ml</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y_test_reduced</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_predict_hls4ml_aq</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy AutoQ Keras:  </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy_keras</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy AutoQ hls4ml: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy_hls4ml</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>The accuracy is slightly lower for this heterogeneously quantized model. Due to some randomness in the optimization procedure, you’re going to have to synthesize this one yourself!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">synth</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">if</span> <span class="n">synth</span><span class="p">:</span>
    <span class="n">hls_model_aq</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">csim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">synth</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">vsynth</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">data_autoq</span> <span class="o">=</span> <span class="n">getReports</span><span class="p">(</span><span class="s1">&#39;autoq_cnn&#39;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Resource usage and latency: AutoQ&quot;</span><span class="p">)</span>
    <span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">data_autoq</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="part5_bdt.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Load dataset</p>
      </div>
    </a>
    <a class="right-next"
       href="part7a_bitstream.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Part 7a: Bitstream Generation</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#start-with-the-neccessary-imports">Start with the neccessary imports</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fetch-the-svhn-dataset-using-tensorflow-dataset">Fetch the SVHN dataset using Tensorflow Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-the-model">Defining the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prune-dense-and-convolutional-layers">Prune dense and convolutional layers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-baseline">Train baseline</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantization-and-the-fused-conv2d-batchnormalization-layer-in-qkeras">Quantization and the fused Conv2D+BatchNormalization layer in QKeras</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#performance">Performance</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#check-sparsity">Check sparsity</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cnns-in-hls4ml">CNNs in hls4ml</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#accuracy-with-bit-accurate-emulation">Accuracy with bit-accurate emulation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#logic-synthesis">Logic synthesis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bonus-exercise-automatic-quantization-with-autoqkeras">Bonus exercise: Automatic quantization with AutoQKeras</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Fast ML team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>